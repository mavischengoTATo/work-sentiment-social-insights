{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb8db4f",
   "metadata": {},
   "source": [
    "## ARM and Networking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef626b7a",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Theory\n",
    "3. Methods\n",
    "4. Results\n",
    "5. Conclusions\n",
    "6. reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60051af",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aee777",
   "metadata": {},
   "source": [
    "### Association rule mining (ARM) is a technique used to discover relationships among a large set of variables in a data set. It has been applied to a variety of industry settings and disciplines but has, to date, not been widely used in the social sciences, especially in education, counseling, and associated disciplines.  And in this part, we want to apply it to our dataset, the tweets with the keywork of new graduate to explore the relationships among this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddfe47f",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "### In data mining and machine learning, association rules are a common unsupervised learning algorithm. Different from the classification and clustering algorithms we have learned before, the main purpose of this type of algorithm is to explore the association between the inherent structural features (i.e. variables) of data.\n",
    "\n",
    "### To put it simply, it is to find some meaningful and valuable relationships in large-scale data sets. With these relationships, on the one hand, we can broaden our understanding of data and its characteristics; On the other hand, it can realize the construction and application of the recommendation system (such as shopping basket analysis).\n",
    "\n",
    "### After we have a basic understanding of association rules, we further subdivide them. Taking the relevance in daily life as an example, among the customers shopping in supermarkets, those who buy bread will buy milk to a large extent. This kind of relevance is called simple association rules; For another example, many customers who buy car sun visors will buy zero glass water in the near future. Such cases not only reflect the relationship between things, but also have a chronological order. Therefore, this kind of association is called sequential association rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a03d39",
   "metadata": {},
   "source": [
    "### Here we hope to explore our last four questions through ARM. We now have many tweets about work, job search, fresh graduates and retirement. We need to summarize these tweets to get four text files to explore people's emotional attitudes from a comprehensive perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a2277",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb840a",
   "metadata": {},
   "source": [
    "#### First, we should import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986ccf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9bbe7",
   "metadata": {},
   "source": [
    "### The following code is needed to read, clean, and convert the tweets into a format suitable for ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd3f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets with the keyword of \"new graduate\"\n",
    "df = pd.read_csv(\"data/01-modified-data/textcleaning_py1.csv\")\n",
    "df = df[[\"id\",\"favorited\",\"retweeted\",\"Clean_Text\"]]\n",
    "df = df.dropna()\n",
    "tweets = df[\"Clean_Text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de24d3",
   "metadata": {},
   "source": [
    "### Utility function: Re-format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0be92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "import pandas as pd \n",
    "\n",
    "def reformat_results(results):\n",
    "\n",
    "    #CLEAN-UP RESULTS \n",
    "    keep=[]\n",
    "    for i in range(0,len(results)):\n",
    "        # print(\"=====================================\")\n",
    "        # print(results[i])\n",
    "        # print(len(list(results[i])))\n",
    "        for j in range(0,len(list(results[i]))):\n",
    "            # print(results)\n",
    "            if(j>1):\n",
    "                for k in range(0,len(list(results[i][j]))):\n",
    "                    if(len(results[i][j][k][0])!=0):\n",
    "                        #print(len(results[i][j][k][0]),results[i][j][k][0])\n",
    "                        rhs=list(results[i][j][k][0])\n",
    "                        lhs=list(results[i][j][k][1])\n",
    "                        conf=float(results[i][j][k][2])\n",
    "                        lift=float(results[i][j][k][3])\n",
    "                        keep.append([rhs,lhs,supp,conf,supp*conf,lift])\n",
    "                        # keep.append()\n",
    "            if(j==1):\n",
    "                supp=results[i][j]\n",
    "\n",
    "    return pd.DataFrame(keep, columns =[\"rhs\",\"lhs\",\"supp\",\"conf\",\"supp x conf\",\"lift\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e761b96",
   "metadata": {},
   "source": [
    "### Utility function: Convert to NetworkX object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ad07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_network(df):\n",
    "    print(df)\n",
    "\n",
    "    #BUILD GRAPH\n",
    "    G = nx.DiGraph()  # DIRECTED\n",
    "    for row in df.iterrows():\n",
    "        # for column in df.columns:\n",
    "        lhs=\"_\".join(row[1][0])\n",
    "        rhs=\"_\".join(row[1][1])\n",
    "        conf=row[1][3]; #print(conf)\n",
    "        if(lhs not in G.nodes): \n",
    "            G.add_node(lhs)\n",
    "        if(rhs not in G.nodes): \n",
    "            G.add_node(rhs)\n",
    "\n",
    "        edge=(lhs,rhs)\n",
    "        if edge not in G.edges:\n",
    "            G.add_edge(lhs, rhs, weight=conf)\n",
    "\n",
    "    # print(G.nodes)\n",
    "    # print(G.edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899cb288",
   "metadata": {},
   "source": [
    "### Utility function: Plot NetworkX object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d88cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(G):\n",
    "    #SPECIFIY X-Y POSITIONS FOR PLOTTING\n",
    "    pos=nx.random_layout(G)\n",
    "\n",
    "    #GENERATE PLOT\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "\n",
    "    #assign colors based on attributes\n",
    "    weights_e \t= [G[u][v]['weight'] for u,v in G.edges()]\n",
    "\n",
    "    #SAMPLE CMAP FOR COLORS \n",
    "    cmap=plt.cm.get_cmap('Blues')\n",
    "    colors_e \t= [cmap(G[u][v]['weight']/5.0) for u,v in G.edges()]\n",
    "\n",
    "    #PLOT\n",
    "    nx.draw(\n",
    "    G,\n",
    "    edgecolors=\"black\",\n",
    "    edge_color=colors_e,\n",
    "    node_size=2000,\n",
    "    linewidths=2,\n",
    "    font_size=8,\n",
    "    font_color=\"white\",\n",
    "    font_weight=\"bold\",\n",
    "    width=weights_e,\n",
    "    with_labels=True,\n",
    "    pos=pos,\n",
    "    ax=ax\n",
    "    )\n",
    "    ax.set(title='Color and size plotted by attribute')\n",
    "    # ax.set_aspect('equal', 'box')\n",
    "    # plt.colorbar(cmap)\n",
    "\n",
    "    # fig.savefig(\"test.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ff7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = []\n",
    "for i in range(500):\n",
    "    a = tweets[i]\n",
    "    alist = a.split(\" \")\n",
    "    tweet.append(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bc18b",
   "metadata": {},
   "source": [
    "# Results\n",
    "### As we can see, there is a network plot, and we want to explore the relationship in tweets with keyword of new graduate. However, as the plot shows below, based on our text processing, we can not get a very useful result, but we can see that these words shows below has a lot of hidden relationship. However, here, we rerun the chuck in the below, but we didn't get the final plot because it depends on the parameter selection, and this process cost a lot of time, so this result doesn't show out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c3e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------tweets with the keyword of tweets------\n",
      "Transactions:         0                1       2         3        4         5          6   \\\n",
      "0       rt     scjchurch_en     new      york  feature      zion  christian   \n",
      "1       rt  arynewsofficial    mbbs  graduate      set       new      world   \n",
      "2       rt         tedchris  number    number     feel      like      world   \n",
      "3       rt         namyrmya    wait        go       to  announce        new   \n",
      "4       rt     concepttvnew    mbbs  graduate    hafiz  muhammad     waleed   \n",
      "..     ...              ...     ...       ...      ...       ...        ...   \n",
      "495  check              new  design    recent       uc  berkeley   graduate   \n",
      "496     rt  arynewsofficial    mbbs  graduate      set       new      world   \n",
      "497     rt  arynewsofficial    mbbs  graduate      set       new      world   \n",
      "498     rt  arynewsofficial    mbbs  graduate      set       new      world   \n",
      "499     rt  arynewsofficial    mbbs  graduate      set       new      world   \n",
      "\n",
      "          7           8                      9   ...         14     15  \\\n",
      "0    mission      center                  break  ...  christian  insti   \n",
      "1     record         win                 number  ...          t     co   \n",
      "2     change      writer                 editor  ...  countless   None   \n",
      "3      actor           s  beoncloudnewyearparty  ...        amp   None   \n",
      "4      malik  ameeruddin                medical  ...     record    win   \n",
      "..       ...         ...                    ...  ...        ...    ...   \n",
      "495  katrina      romulo                    ceo  ...          t     co   \n",
      "496   record         win                 number  ...          t     co   \n",
      "497   record         win                 number  ...          t     co   \n",
      "498   record         win                 number  ...          t     co   \n",
      "499   record         win                 number  ...          t     co   \n",
      "\n",
      "                       16      17     18    19    20    21    22    23  \n",
      "0                    None    None   None  None  None  None  None  None  \n",
      "1    nbnumberyasdvznumber  arynew  https     t  None  None  None  None  \n",
      "2                    None    None   None  None  None  None  None  None  \n",
      "3                    None    None   None  None  None  None  None  None  \n",
      "4                  number    gold   None  None  None  None  None  None  \n",
      "..                    ...     ...    ...   ...   ...   ...   ...   ...  \n",
      "495   jnumberrahpysnumber    None   None  None  None  None  None  None  \n",
      "496  nbnumberyasdvznumber  arynew  https     t  None  None  None  None  \n",
      "497  nbnumberyasdvznumber  arynew  https     t  None  None  None  None  \n",
      "498  nbnumberyasdvznumber  arynew  https     t  None  None  None  None  \n",
      "499  nbnumberyasdvznumber  arynew  https     t  None  None  None  None  \n",
      "\n",
      "[500 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------tweets with the keyword of tweets------\")\n",
    "print(\"Transactions:\",pd.DataFrame(tweet))\n",
    "results = list(apriori(tweet, min_support=0.06, min_confidence=0.3, min_lift=3, min_length=1))     #RUN APRIORI ALGORITHM\n",
    "pd_results=reformat_results(results)\n",
    "print(\"Results\\n\",pd_results)\n",
    "G=convert_to_network(pd_results)\n",
    "plot_network(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4321547",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d6191",
   "metadata": {},
   "source": [
    "### In the future exploration, we can focus on the connections between words shown on the figure and make some important explorations. Focusing on the words themselves, we can find some representative words in the context of a keyword, and there are words connected with many words, which is more and more intuitive than the information that word cloud brings us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b43675",
   "metadata": {},
   "source": [
    "# Reference\n",
    "### https://link.springer.com/article/10.3758/BF03193156"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
